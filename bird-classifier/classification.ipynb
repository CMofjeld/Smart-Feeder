{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAO Image Classification \n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n",
    "\n",
    "Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n",
    "\n",
    "* Take a pretrained resnet18 model and finetune on a sample dataset converted from PascalVOC\n",
    "* Prune the finetuned model\n",
    "* Retrain the pruned model to recover lost accuracy\n",
    "* Export the pruned model\n",
    "* Run Inference on the trained model\n",
    "* Export the pruned and retrained model to a .etlt file for deployment to DeepStream\n",
    "\n",
    "### Table of Contents\n",
    "This notebook shows an example use case for classification using the Train Adapt Optimize (TAO) Toolkit.\n",
    "\n",
    "0. [Set up env variables and map drives](#head-0)\n",
    "1. [Installing the TAO Launcher](#head-1)\n",
    "2. [Prepare dataset and pretrained model](#head-2)\n",
    "    1. [Split the dataset into train/test/val](#head-2-1)\n",
    "    2. [Download pre-trained model](#head-2-2)\n",
    "3. [Provide training specfication](#head-3)\n",
    "4. [Run TAO training](#head-4)\n",
    "5. [Evaluate trained models](#head-5)\n",
    "6. [Prune trained models](#head-6)\n",
    "7. [Retrain pruned models](#head-7)\n",
    "8. [Testing the model](#head-8)\n",
    "9. [Visualize inferences](#head-9)\n",
    "10. [Export and Deploy!](#head-10)\n",
    "    1. [Int8 Optimization](#head-10-1)\n",
    "    2. [Generate TensorRT engine](#head-10-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up env variables and map drives <a class=\"anchor\" id=\"head-0\"></a>\n",
    "When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n",
    "\n",
    "The following notebook requires the user to set an env variable called the `$LOCAL_PROJECT_DIR` as the path to the users workspace. Please note that the dataset to run this notebook is expected to reside in the `$LOCAL_PROJECT_DIR/data`, while the TAO experiment generated collaterals will be output to `$LOCAL_PROJECT_DIR/classification`. More information on how to set up the dataset and the supported steps in the TAO workflow are provided in the subsequent cells.\n",
    "\n",
    "*Note: Please make sure to remove any stray artifacts/files from the `$USER_EXPERIMENT_DIR` or `$DATA_DOWNLOAD_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*\n",
    "\n",
    "*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KEY=nvidia_tlt\n",
      "env: NUM_GPUS=1\n",
      "env: USER_EXPERIMENT_DIR=/workspace/tao-experiments/classification\n",
      "env: DATA_DOWNLOAD_DIR=/workspace/tao-experiments/data\n",
      "env: SPECS_DIR=/workspace/tao-experiments/classification/specs\n",
      "total 8\n",
      "-rw-rw-r-- 1 carl carl 1329 Oct 19 12:52 classification_spec.cfg\n",
      "-rw-rw-r-- 1 carl carl 1234 Oct 19 14:16 classification_retrain_spec.cfg\n"
     ]
    }
   ],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "import os\n",
    "\n",
    "%env KEY=nvidia_tlt\n",
    "%env NUM_GPUS=1\n",
    "%env USER_EXPERIMENT_DIR=/workspace/tao-experiments/classification\n",
    "%env DATA_DOWNLOAD_DIR=/workspace/tao-experiments/data\n",
    "\n",
    "# Set this path if you don't run the notebook from the samples directory.\n",
    "# %env NOTEBOOK_ROOT=~/tao-samples/classification\n",
    "\n",
    "# Please define this local project directory that needs to be mapped to the TAO docker session.\n",
    "# The dataset expected to be present in $LOCAL_PROJECT_DIR/data, while the results for the steps\n",
    "# in this notebook will be stored at $LOCAL_PROJECT_DIR/classification\n",
    "# !PLEASE MAKE SURE TO UPDATE THIS PATH!.\n",
    "os.environ[\"LOCAL_PROJECT_DIR\"] = os.getcwd()\n",
    "\n",
    "os.environ[\"LOCAL_DATA_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"data\"\n",
    ")\n",
    "os.environ[\"LOCAL_EXPERIMENT_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"classification\"\n",
    ")\n",
    "\n",
    "# The sample spec files are present in the same path as the downloaded samples.\n",
    "os.environ[\"LOCAL_SPECS_DIR\"] = os.path.join(\n",
    "    os.getenv(\"NOTEBOOK_ROOT\", os.getcwd()),\n",
    "    \"specs\"\n",
    ")\n",
    "%env SPECS_DIR=/workspace/tao-experiments/classification/specs\n",
    "\n",
    "# Showing list of specification files.\n",
    "!ls -rlt $LOCAL_SPECS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below maps the project directory on your local host to a workspace directory in the TAO docker instance, so that the data and the results are mapped from outside to inside of the docker instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping up the local directories to the TAO docker.\n",
    "import json\n",
    "import os\n",
    "mounts_file = os.path.expanduser(\"~/.tao_mounts.json\")\n",
    "\n",
    "# Define the dictionary with the mapped drives\n",
    "drive_map = {\n",
    "    \"Mounts\": [\n",
    "        # Mapping the data directory\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "            \"destination\": \"/workspace/tao-experiments\"\n",
    "        },\n",
    "        # Mapping the specs directory.\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_SPECS_DIR\"],\n",
    "            \"destination\": os.environ[\"SPECS_DIR\"]\n",
    "        },\n",
    "    ],\n",
    "    \"DockerOptions\":{\n",
    "        \"user\": \"{}:{}\".format(os.getuid(), os.getgid())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Writing the mounts file.\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(drive_map, mfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Mounts\": [\n",
      "        {\n",
      "            \"source\": \"/home/carl/bird-classifier\",\n",
      "            \"destination\": \"/workspace/tao-experiments\"\n",
      "        },\n",
      "        {\n",
      "            \"source\": \"/home/carl/bird-classifier/specs\",\n",
      "            \"destination\": \"/workspace/tao-experiments/classification/specs\"\n",
      "        }\n",
      "    ],\n",
      "    \"DockerOptions\": {\n",
      "        \"user\": \"1000:1000\"\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.tao_mounts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing the TAO launcher <a class=\"anchor\" id=\"head-1\"></a>\n",
    "The TAO launcher is a python package distributed as a python wheel listed in the `nvidia-pyindex` python index. You may install the launcher by executing the following cell.\n",
    "\n",
    "Please note that TAO Toolkit recommends users to run the TAO launcher in a virtual env with python 3.6.9. You may follow the instruction in this [page](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) to set up a python virtual env using the `virtualenv` and `virtualenvwrapper` packages. Once you have setup virtualenvwrapper, please set the version of python to be used in the virtual env by using the `VIRTUALENVWRAPPER_PYTHON` variable. You may do so by running\n",
    "\n",
    "```sh\n",
    "export VIRTUALENVWRAPPER_PYTHON=/path/to/bin/python3.x\n",
    "```\n",
    "where x >= 6 and <= 8\n",
    "\n",
    "We recommend performing this step first and then launching the notebook from the virtual environment. In addition to installing TAO python package, please make sure of the following software requirements:\n",
    "* python >=3.6.9 < 3.8.x\n",
    "* docker-ce > 19.03.5\n",
    "* docker-API 1.40\n",
    "* nvidia-container-toolkit > 1.3.0-1\n",
    "* nvidia-container-runtime > 3.4.0-1\n",
    "* nvidia-docker2 > 2.5.0-1\n",
    "* nvidia-driver > 455+\n",
    "\n",
    "Once you have installed the pre-requisites, please log in to the docker registry nvcr.io by following the command below\n",
    "\n",
    "```sh\n",
    "docker login nvcr.io\n",
    "```\n",
    "\n",
    "You will be trigerred to enter a username and password. The username is `$oauthtoken` and the password is the API key generated from `ngc.nvidia.com`. Please follow the instructions in the [NGC setup guide](https://docs.nvidia.com/ngc/ngc-overview/index.html#generating-api-key) to generate your own API key.\n",
    "\n",
    "Please note that TAO Toolkit recommends users to run the TAO launcher in a virtual env with python 3.6.9. You may follow the instruction in this [page](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) to set up a python virtual env using the `virtualenv` and `virtualenvwrapper` packages. Once you have setup virtualenvwrapper, please set the version of python to be used in the virtual env by using the `VIRTUALENVWRAPPER_PYTHON` variable. You may do so by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this cell IF you have already installed the TAO launcher.\n",
    "!pip3 install nvidia-pyindex\n",
    "!pip3 install nvidia-tao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration of the TAO Toolkit Instance\n",
      "dockers: ['nvidia/tao/tao-toolkit-tf', 'nvidia/tao/tao-toolkit-pyt', 'nvidia/tao/tao-toolkit-lm']\n",
      "format_version: 1.0\n",
      "toolkit_version: 3.21.08\n",
      "published_date: 08/17/2021\n"
     ]
    }
   ],
   "source": [
    "# View the versions of the TAO launcher\n",
    "!tao info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare datasets and pre-trained model <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the pascal VOC dataset for the tutorial. To find more details please visit \n",
    "http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit. Please download the dataset present at http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to $DATA_DOWNLOAD_DIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that file is present\n",
    "import os\n",
    "DATA_DIR = os.environ.get('LOCAL_DATA_DIR')\n",
    "print(DATA_DIR)\n",
    "if not os.path.isfile(os.path.join(DATA_DIR , 'VOCtrainval_11-May-2012.tar')):\n",
    "    print('tar file for dataset not found. Please download.')\n",
    "else:\n",
    "    print('Found dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack \n",
    "!tar -xvf $LOCAL_DATA_DIR/VOCtrainval_11-May-2012.tar -C $LOCAL_DATA_DIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "!ls $LOCAL_DATA_DIR/VOCdevkit/VOC2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Split the dataset into train/val/test <a class=\"anchor\" id=\"head-1-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pascal VOC Dataset is converted to our format (for classification) and then to train/val/test in the next two blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pip requirements\n",
    "!pip3 install tqdm\n",
    "!pip3 install matplotlib==3.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as join_path\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "DATA_DIR=os.environ.get('LOCAL_DATA_DIR')\n",
    "source_dir = join_path(DATA_DIR, \"VOCdevkit/VOC2012\")\n",
    "target_dir = join_path(DATA_DIR, \"formatted\")\n",
    "\n",
    "\n",
    "suffix = '_trainval.txt'\n",
    "classes_dir = join_path(source_dir, \"ImageSets\", \"Main\")\n",
    "images_dir = join_path(source_dir, \"JPEGImages\")\n",
    "classes_files = glob.glob(classes_dir+\"/*\"+suffix)\n",
    "for file in classes_files:\n",
    "    # get the filename and make output class folder\n",
    "    classname = os.path.basename(file)\n",
    "    if classname.endswith(suffix):\n",
    "        classname = classname[:-len(suffix)]\n",
    "        target_dir_path = join_path(target_dir, classname)\n",
    "        if not os.path.exists(target_dir_path):\n",
    "            os.makedirs(target_dir_path)\n",
    "    else:\n",
    "        continue\n",
    "    print(classname)\n",
    "\n",
    "\n",
    "    with open(file) as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "\n",
    "    for line in content:\n",
    "        tokens = re.split('\\s+', line)\n",
    "        if tokens[1] == '1':\n",
    "            # copy this image into target dir_path\n",
    "            target_file_path = join_path(target_dir_path, tokens[0] + '.jpg')\n",
    "            src_file_path = join_path(images_dir, tokens[0] + '.jpg')\n",
    "            shutil.copyfile(src_file_path, target_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR=os.environ.get('LOCAL_DATA_DIR')\n",
    "SOURCE_DIR=os.path.join(DATA_DIR, 'formatted')\n",
    "TARGET_DIR=os.path.join(DATA_DIR,'split')\n",
    "# list dir\n",
    "print(os.walk(SOURCE_DIR))\n",
    "dir_list = next(os.walk(SOURCE_DIR))[1]\n",
    "# for each dir, create a new dir in split\n",
    "for dir_i in tqdm(dir_list):\n",
    "        newdir_train = os.path.join(TARGET_DIR, 'train', dir_i)\n",
    "        newdir_val = os.path.join(TARGET_DIR, 'val', dir_i)\n",
    "        newdir_test = os.path.join(TARGET_DIR, 'test', dir_i)\n",
    "        \n",
    "        if not os.path.exists(newdir_train):\n",
    "                os.makedirs(newdir_train)\n",
    "        if not os.path.exists(newdir_val):\n",
    "                os.makedirs(newdir_val)\n",
    "        if not os.path.exists(newdir_test):\n",
    "                os.makedirs(newdir_test)\n",
    "\n",
    "        img_list = glob.glob(os.path.join(SOURCE_DIR, dir_i, '*.jpg'))\n",
    "        # shuffle data\n",
    "        shuffle(img_list)\n",
    "\n",
    "        for j in range(int(len(img_list)*0.7)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'train', dir_i))\n",
    "\n",
    "        for j in range(int(len(img_list)*0.7), int(len(img_list)*0.8)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'val', dir_i))\n",
    "                \n",
    "        for j in range(int(len(img_list)*0.8), len(img_list)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'test', dir_i))\n",
    "                \n",
    "print('Done splitting dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $LOCAL_DATA_DIR/split/test/cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Download pretrained models <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will use NGC CLI to get the pre-trained models. For more details, go to ngc.nvidia.com and click the SETUP on the navigation bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLI=ngccli_cat_linux.zip\n",
      "--2021-10-19 12:33:27--  https://ngc.nvidia.com/downloads/ngccli_cat_linux.zip\n",
      "Resolving ngc.nvidia.com (ngc.nvidia.com)... 65.8.158.9, 65.8.158.99, 65.8.158.42, ...\n",
      "Connecting to ngc.nvidia.com (ngc.nvidia.com)|65.8.158.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25097830 (24M) [application/zip]\n",
      "Saving to: ‘/home/carl/bird-classifier/ngccli/ngccli_cat_linux.zip’\n",
      "\n",
      "ngccli_cat_linux.zi 100%[===================>]  23.93M  22.0MB/s    in 1.1s    \n",
      "\n",
      "2021-10-19 12:33:28 (22.0 MB/s) - ‘/home/carl/bird-classifier/ngccli/ngccli_cat_linux.zip’ saved [25097830/25097830]\n",
      "\n",
      "Archive:  /home/carl/bird-classifier/ngccli/ngccli_cat_linux.zip\n",
      "  inflating: /home/carl/bird-classifier/ngccli/ngc  \n",
      " extracting: /home/carl/bird-classifier/ngccli/ngc.md5  \n"
     ]
    }
   ],
   "source": [
    "# Installing NGC CLI on the local machine.\n",
    "## Download and install\n",
    "%env CLI=ngccli_cat_linux.zip\n",
    "!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n",
    "\n",
    "# Remove any previously existing CLI installations\n",
    "!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n",
    "!unzip -u \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n",
    "!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| Versi | Accur | Epoch | Batch | GPU   | Memor | File  | Statu | Creat |\n",
      "| on    | acy   | s     | Size  | Model | y Foo | Size  | s     | ed    |\n",
      "|       |       |       |       |       | tprin |       |       | Date  |\n",
      "|       |       |       |       |       | t     |       |       |       |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| vgg19 | 77.56 | 80    | 1     | V100  | 153.7 | 153.7 | UPLOA | Aug   |\n",
      "|       |       |       |       |       |       | 2 MB  | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| vgg16 | 77.17 | 80    | 1     | V100  | 113.2 | 113.1 | UPLOA | Aug   |\n",
      "|       |       |       |       |       |       | 6 MB  | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| squee | 65.13 | 80    | 1     | V100  | 6.5   | 6.46  | UPLOA | Aug   |\n",
      "| zenet |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| resne | 77.91 | 80    | 1     | V100  | 294.2 | 294.2 | UPLOA | Aug   |\n",
      "| t50   |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| resne | 77.04 | 80    | 1     | V100  | 170.7 | 170.6 | UPLOA | Aug   |\n",
      "| t34   |       |       |       |       |       | 5 MB  | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| resne | 76.74 | 80    | 1     | V100  | 89.0  | 88.96 | UPLOA | Aug   |\n",
      "| t18   |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| resne | 77.78 | 80    | 1     | V100  | 576.3 | 576.3 | UPLOA | Aug   |\n",
      "| t101  |       |       |       |       |       | 3 MB  | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| resne | 74.38 | 80    | 1     | V100  | 38.3  | 38.31 | UPLOA | Aug   |\n",
      "| t10   |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| mobil | 72.75 | 80    | 1     | V100  | 5.0   | 5.01  | UPLOA | Aug   |\n",
      "| enet_ |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "| v2    |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| mobil | 79.5  | 80    | 1     | V100  | 26.2  | 26.22 | UPLOA | Aug   |\n",
      "| enet_ |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "| v1    |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| googl | 77.11 | 80    | 1     | V100  | 47.6  | 47.64 | UPLOA | Aug   |\n",
      "| enet  |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| effic | 77.11 | 80    | 1     | V100  | 26.8  | 26.78 | UPLOA | Aug   |\n",
      "| ientn |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "| et_b1 |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| _swis |       |       |       |       |       |       |       |       |\n",
      "| h     |       |       |       |       |       |       |       |       |\n",
      "| effic | 77.11 | 80    | 1     | V100  | 26.8  | 26.78 | UPLOA | Aug   |\n",
      "| ientn |       |       |       |       |       | MB    | D_COM | 18,   |\n",
      "| et_b1 |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| _relu |       |       |       |       |       |       |       |       |\n",
      "| darkn | 76.44 | 80    | 1     | V100  | 311.7 | 311.6 | UPLOA | Aug   |\n",
      "| et53  |       |       |       |       |       | 8 MB  | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| darkn | 77.52 | 80    | 1     | V100  | 152.8 | 152.8 | UPLOA | Aug   |\n",
      "| et19  |       |       |       |       |       | 2 MB  | D_COM | 18,   |\n",
      "|       |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| cspda | 76.44 | 80    | 1     | V100  | 103.0 | 102.9 | UPLOA | Sep   |\n",
      "| rknet |       |       |       |       |       | 9 MB  | D_COM | 10,   |\n",
      "| 53    |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| cspda | 77.52 | 80    | 1     | V100  | 62.9  | 62.86 | UPLOA | Sep   |\n",
      "| rknet |       |       |       |       |       | MB    | D_COM | 10,   |\n",
      "| 19    |       |       |       |       |       |       | PLETE | 2021  |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "!ngc registry model list nvidia/tao/pretrained_classification:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/pretrained_vgg19/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 142.58 MB in 9s, Download speed: 15.83 MB/s               \n",
      "----------------------------------------------------\n",
      "Transfer id: pretrained_classification_vvgg19 Download status: Completed.\n",
      "Downloaded local path: /home/carl/bird-classifier/classification/pretrained_vgg19/pretrained_classification_vvgg19\n",
      "Total files downloaded: 1 \n",
      "Total downloaded size: 142.58 MB\n",
      "Started at: 2021-10-19 12:40:44.495356\n",
      "Completed at: 2021-10-19 12:40:53.505335\n",
      "Duration taken: 9s\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pull pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tao/pretrained_classification:vgg19 --dest $LOCAL_EXPERIMENT_DIR/pretrained_vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that model is downloaded into dir.\n",
      "total 157408\n",
      "-rw------- 1 carl carl 161183816 Oct 19 12:40 vgg_19.hdf5\n"
     ]
    }
   ],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $LOCAL_EXPERIMENT_DIR/pretrained_vgg19/pretrained_classification_vvgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Provide training specfication <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* Training dataset\n",
    "* Validation dataset\n",
    "* Pre-trained models\n",
    "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config {\n",
      "  arch: \"vgg\",\n",
      "  n_layers: 19\n",
      "  # Setting these parameters to true to match the template downloaded from NGC.\n",
      "  use_batch_norm: true\n",
      "  all_projections: true\n",
      "  freeze_blocks: 0\n",
      "  freeze_blocks: 1\n",
      "  input_image_size: \"3,224,224\"\n",
      "}\n",
      "train_config {\n",
      "  train_dataset_path: \"/workspace/tao-experiments/data/split/train\"\n",
      "  val_dataset_path: \"/workspace/tao-experiments/data/split/val\"\n",
      "  pretrained_model_path: \"/workspace/tao-experiments/classification/output/weights/resnet_040.tlt\"\n",
      "  optimizer {\n",
      "    sgd {\n",
      "    lr: 0.01\n",
      "    decay: 0.0\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "  }\n",
      "}\n",
      "  batch_size_per_gpu: 64\n",
      "  n_epochs: 80\n",
      "  n_workers: 16\n",
      "  preprocess_mode: \"caffe\"\n",
      "  enable_random_crop: True\n",
      "  enable_center_crop: True\n",
      "  label_smoothing: 0.0\n",
      "  mixup_alpha: 0.1\n",
      "  # regularizer\n",
      "  reg_config {\n",
      "    type: \"L2\"\n",
      "    scope: \"Conv2D,Dense\"\n",
      "    weight_decay: 0.00005\n",
      "  }\n",
      "\n",
      "  # learning_rate\n",
      "  lr_config {\n",
      "    soft_anneal {\n",
      "      learning_rate: 0.05\n",
      "      soft_start: 0.056\n",
      "      annealing_points: 0.3\n",
      "      annealing_points: 0.6\n",
      "      annealing_points: 0.8\n",
      "      annealing_divider: 10\n",
      "    }\n",
      "  }\n",
      "}\n",
      "eval_config {\n",
      "  eval_dataset_path: \"/workspace/tao-experiments/data/split/test\"\n",
      "  model_path: \"/workspace/tao-experiments/classification/output/weights/vgg_080.tlt\"\n",
      "  top_k: 1\n",
      "  batch_size: 32\n",
      "  n_workers: 8\n",
      "  enable_center_crop: True\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_SPECS_DIR/classification_spec.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run TAO training <a class=\"anchor\" id=\"head-4\"></a>\n",
    "* Provide the sample spec file and the output directory location for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-19 12:54:09,794 [INFO] root: Registry: ['nvcr.io']\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-9979ze11 because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:281: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:290: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2021-10-19 19:54:15,652 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-10-19 19:54:15,652 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-10-19 19:54:15,652 [INFO] __main__: Default image mean [103.939, 116.779, 123.68] will be used.\n",
      "Found 9430 images belonging to 200 classes.\n",
      "2021-10-19 19:54:15,975 [INFO] __main__: Processing dataset (train): /workspace/tao-experiments/data/split/train\n",
      "Found 1179 images belonging to 200 classes.\n",
      "2021-10-19 19:54:16,081 [INFO] __main__: Processing dataset (validation): /workspace/tao-experiments/data/split/val\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-10-19 19:54:16,081 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-10-19 19:54:16,083 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-10-19 19:54:16,097 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-10-19 19:54:16,101 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-10-19 19:54:16,474 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-10-19 19:54:16,814 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-10-19 19:54:16,814 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-10-19 19:54:16,949 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-10-19 19:54:18,928 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-10-19 19:54:18,931 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-10-19 19:54:19,764 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-10-19 19:54:19,857 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 112, 112) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 112, 112) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 112, 112) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 56, 56)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 56, 56)   256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 56, 56)   0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 56, 56)   36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 56, 56)   4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 56, 56)   0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 56, 56)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 56, 56)   36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 56, 56)   0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 56, 56)   36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 56, 56)   4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 56, 56)   0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 56, 56)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 28, 28)  73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 28, 28)  512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 28, 28)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 28, 28)  147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 28, 28)  8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 28, 28)  512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 28, 28)  512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 28, 28)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 28, 28)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 28, 28)  147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 28, 28)  512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 28, 28)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 28, 28)  147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 28, 28)  16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 28, 28)  512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 28, 28)  512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 28, 28)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 28, 28)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 14, 14)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 14, 14)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 14, 14)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 14, 14)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 14, 14)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 14, 14)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 14, 14)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 14, 14)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 14, 14)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 14, 14)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 14, 14)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 14, 14)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 14, 14)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 14, 14)  1179648     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 14, 14)  131072      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 14, 14)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 14, 14)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 14, 14)  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 14, 14)  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 14, 14)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 14, 14)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 512, 1, 1)    0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 200)          102600      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,645,064\n",
      "Trainable params: 11,468,360\n",
      "Non-trainable params: 176,704\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:929: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "2021-10-19 19:54:40,295 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:929: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:931: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2021-10-19 19:54:40,295 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:931: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/80\n",
      "  1/148 [..............................] - ETA: 1:08:32 - loss: 2.5076 - acc: 0.5781WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:146: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "2021-10-19 19:55:10,850 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:146: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "  2/148 [..............................] - ETA: 35:50 - loss: 2.5128 - acc: 0.5234  /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.651669). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "148/148 [==============================] - 61s 411ms/step - loss: 2.5372 - acc: 0.5293 - val_loss: 1.9380 - val_acc: 0.5386\n",
      "a317adb23278:82:110 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.3<0>\n",
      "a317adb23278:82:110 [0] NCCL INFO NET/Plugin : Plugin load returned 0 : libnccl-net.so: cannot open shared object file: No such file or directory.\n",
      "a317adb23278:82:110 [0] NCCL INFO NET/IB : No device found.\n",
      "a317adb23278:82:110 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.3<0>\n",
      "a317adb23278:82:110 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda11.1\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 00/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 01/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 02/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 03/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 04/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 05/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 06/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 07/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 08/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 09/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 10/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 11/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 12/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 13/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 14/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 15/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 16/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 17/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 18/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 19/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 20/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 21/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 22/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 23/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 24/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 25/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 26/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 27/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 28/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 29/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 30/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Channel 31/32 :    0\n",
      "a317adb23278:82:110 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [1] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [2] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [3] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [4] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [5] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [6] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [7] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [8] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [9] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [10] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [11] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [12] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [13] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [14] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [15] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [16] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [17] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [18] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [19] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [20] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [21] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [22] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [23] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [24] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [25] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [26] -1/-1/-1->0->-1|-1->0->-1/\n",
      "a317adb23278:82:110 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "a317adb23278:82:110 [0] NCCL INFO comm 0x7f04c2f8e930 rank 0 nranks 1 cudaDev 0 busId 9000 - Init COMPLETE\n",
      "Epoch 2/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 2.5689 - acc: 0.4957 - val_loss: 2.2771 - val_acc: 0.4623\n",
      "Epoch 3/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 2.5896 - acc: 0.4801 - val_loss: 2.6682 - val_acc: 0.4063\n",
      "Epoch 4/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 2.6166 - acc: 0.4739 - val_loss: 2.5762 - val_acc: 0.4453\n",
      "Epoch 5/80\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 2.5813 - acc: 0.4870 - val_loss: 2.2909 - val_acc: 0.4716\n",
      "Epoch 6/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 2.4209 - acc: 0.5330 - val_loss: 2.0651 - val_acc: 0.5445\n",
      "Epoch 7/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 2.2071 - acc: 0.5938 - val_loss: 1.8005 - val_acc: 0.5997\n",
      "Epoch 8/80\n",
      "148/148 [==============================] - 31s 212ms/step - loss: 2.1157 - acc: 0.6214 - val_loss: 1.7352 - val_acc: 0.6158\n",
      "Epoch 9/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 2.0381 - acc: 0.6446 - val_loss: 1.7729 - val_acc: 0.6200\n",
      "Epoch 10/80\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.9701 - acc: 0.6611 - val_loss: 1.7060 - val_acc: 0.6370\n",
      "Epoch 11/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.8923 - acc: 0.6937 - val_loss: 1.7923 - val_acc: 0.6378\n",
      "Epoch 12/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.8606 - acc: 0.6998 - val_loss: 1.5955 - val_acc: 0.6590\n",
      "Epoch 13/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.8018 - acc: 0.7219 - val_loss: 1.6020 - val_acc: 0.6751\n",
      "Epoch 14/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.7925 - acc: 0.7264 - val_loss: 1.6596 - val_acc: 0.6489\n",
      "Epoch 15/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.7707 - acc: 0.7323 - val_loss: 1.5601 - val_acc: 0.6836\n",
      "Epoch 16/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.7195 - acc: 0.7473 - val_loss: 1.6991 - val_acc: 0.6684\n",
      "Epoch 17/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.6794 - acc: 0.7621 - val_loss: 1.5297 - val_acc: 0.7142\n",
      "Epoch 18/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.6546 - acc: 0.7714 - val_loss: 1.5266 - val_acc: 0.6955\n",
      "Epoch 19/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.6284 - acc: 0.7768 - val_loss: 1.6328 - val_acc: 0.6828\n",
      "Epoch 20/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.6312 - acc: 0.7812 - val_loss: 1.5955 - val_acc: 0.6904\n",
      "Epoch 21/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.6154 - acc: 0.7909 - val_loss: 1.5873 - val_acc: 0.6930\n",
      "Epoch 22/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 1.6034 - acc: 0.7895 - val_loss: 1.5930 - val_acc: 0.6938\n",
      "Epoch 23/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.5806 - acc: 0.7998 - val_loss: 1.6938 - val_acc: 0.6768\n",
      "Epoch 24/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.5849 - acc: 0.8011 - val_loss: 1.5781 - val_acc: 0.6938\n",
      "Epoch 25/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.4999 - acc: 0.8225 - val_loss: 1.3600 - val_acc: 0.7405\n",
      "Epoch 26/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.3829 - acc: 0.8592 - val_loss: 1.3227 - val_acc: 0.7566\n",
      "Epoch 27/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 1.3460 - acc: 0.8799 - val_loss: 1.3148 - val_acc: 0.7557\n",
      "Epoch 28/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 1.3130 - acc: 0.8800 - val_loss: 1.2978 - val_acc: 0.7566\n",
      "Epoch 29/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.3333 - acc: 0.8779 - val_loss: 1.3060 - val_acc: 0.7523\n",
      "Epoch 30/80\n",
      "148/148 [==============================] - 32s 218ms/step - loss: 1.3284 - acc: 0.8767 - val_loss: 1.2892 - val_acc: 0.7591\n",
      "Epoch 31/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.3047 - acc: 0.8839 - val_loss: 1.2834 - val_acc: 0.7651\n",
      "Epoch 32/80\n",
      "148/148 [==============================] - 32s 218ms/step - loss: 1.2756 - acc: 0.8922 - val_loss: 1.3000 - val_acc: 0.7625\n",
      "Epoch 33/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 1.2865 - acc: 0.8881 - val_loss: 1.2946 - val_acc: 0.7566\n",
      "Epoch 34/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 1.2937 - acc: 0.8906 - val_loss: 1.3157 - val_acc: 0.7574\n",
      "Epoch 35/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2634 - acc: 0.8927 - val_loss: 1.3088 - val_acc: 0.7523\n",
      "Epoch 36/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 1.3080 - acc: 0.8826 - val_loss: 1.2990 - val_acc: 0.7574\n",
      "Epoch 37/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 1.2268 - acc: 0.8980 - val_loss: 1.2944 - val_acc: 0.7600\n",
      "Epoch 38/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 1.2451 - acc: 0.8987 - val_loss: 1.3015 - val_acc: 0.7634\n",
      "Epoch 39/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2414 - acc: 0.8967 - val_loss: 1.2829 - val_acc: 0.7625\n",
      "Epoch 40/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2532 - acc: 0.8938 - val_loss: 1.2883 - val_acc: 0.7642\n",
      "Epoch 41/80\n",
      "148/148 [==============================] - 33s 221ms/step - loss: 1.2537 - acc: 0.8932 - val_loss: 1.2986 - val_acc: 0.7625\n",
      "Epoch 42/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2286 - acc: 0.8987 - val_loss: 1.2972 - val_acc: 0.7727\n",
      "Epoch 43/80\n",
      "148/148 [==============================] - 32s 218ms/step - loss: 1.2351 - acc: 0.9025 - val_loss: 1.3003 - val_acc: 0.7718\n",
      "Epoch 44/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2317 - acc: 0.8987 - val_loss: 1.2910 - val_acc: 0.7735\n",
      "Epoch 45/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2059 - acc: 0.9061 - val_loss: 1.3046 - val_acc: 0.7812\n",
      "Epoch 46/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 1.2146 - acc: 0.9030 - val_loss: 1.3020 - val_acc: 0.7701\n",
      "Epoch 47/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 1.2192 - acc: 0.9033 - val_loss: 1.3035 - val_acc: 0.7651\n",
      "Epoch 48/80\n",
      "148/148 [==============================] - 33s 221ms/step - loss: 1.2116 - acc: 0.8996 - val_loss: 1.3060 - val_acc: 0.7668\n",
      "Epoch 49/80\n",
      "148/148 [==============================] - 33s 221ms/step - loss: 1.2249 - acc: 0.9044 - val_loss: 1.3056 - val_acc: 0.7718\n",
      "Epoch 50/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.2049 - acc: 0.9037 - val_loss: 1.3134 - val_acc: 0.7710\n",
      "Epoch 51/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.2319 - acc: 0.9008 - val_loss: 1.3069 - val_acc: 0.7744\n",
      "Epoch 52/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.2087 - acc: 0.9060 - val_loss: 1.3028 - val_acc: 0.7676\n",
      "Epoch 53/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1826 - acc: 0.9083 - val_loss: 1.3011 - val_acc: 0.7718\n",
      "Epoch 54/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.2190 - acc: 0.9024 - val_loss: 1.3136 - val_acc: 0.7718\n",
      "Epoch 55/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1943 - acc: 0.9038 - val_loss: 1.3055 - val_acc: 0.7701\n",
      "Epoch 56/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.2104 - acc: 0.9029 - val_loss: 1.3075 - val_acc: 0.7684\n",
      "Epoch 57/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.2030 - acc: 0.9089 - val_loss: 1.3052 - val_acc: 0.7761\n",
      "Epoch 58/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.2061 - acc: 0.9036 - val_loss: 1.3062 - val_acc: 0.7676\n",
      "Epoch 59/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1991 - acc: 0.9029 - val_loss: 1.3016 - val_acc: 0.7710\n",
      "Epoch 60/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1928 - acc: 0.9067 - val_loss: 1.3072 - val_acc: 0.7684\n",
      "Epoch 61/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.2039 - acc: 0.9002 - val_loss: 1.3000 - val_acc: 0.7710\n",
      "Epoch 62/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 1.2031 - acc: 0.9050 - val_loss: 1.2974 - val_acc: 0.7701\n",
      "Epoch 63/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 1.1996 - acc: 0.9037 - val_loss: 1.2912 - val_acc: 0.7744\n",
      "Epoch 64/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1915 - acc: 0.9069 - val_loss: 1.2958 - val_acc: 0.7710\n",
      "Epoch 65/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1898 - acc: 0.9105 - val_loss: 1.2909 - val_acc: 0.7693\n",
      "Epoch 66/80\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.1694 - acc: 0.9123 - val_loss: 1.3020 - val_acc: 0.7710\n",
      "Epoch 67/80\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.1911 - acc: 0.9078 - val_loss: 1.2974 - val_acc: 0.7710\n",
      "Epoch 68/80\n",
      "148/148 [==============================] - 31s 213ms/step - loss: 1.1999 - acc: 0.9067 - val_loss: 1.3011 - val_acc: 0.7710\n",
      "Epoch 69/80\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.2274 - acc: 0.9033 - val_loss: 1.2977 - val_acc: 0.7659\n",
      "Epoch 70/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.1929 - acc: 0.9126 - val_loss: 1.3008 - val_acc: 0.7693\n",
      "Epoch 71/80\n",
      "148/148 [==============================] - 31s 212ms/step - loss: 1.1890 - acc: 0.9096 - val_loss: 1.3030 - val_acc: 0.7668\n",
      "Epoch 72/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 1.1757 - acc: 0.9086 - val_loss: 1.2977 - val_acc: 0.7693\n",
      "Epoch 73/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.1878 - acc: 0.9099 - val_loss: 1.2994 - val_acc: 0.7668\n",
      "Epoch 74/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.1987 - acc: 0.9061 - val_loss: 1.3011 - val_acc: 0.7659\n",
      "Epoch 75/80\n",
      "148/148 [==============================] - 32s 213ms/step - loss: 1.1859 - acc: 0.9084 - val_loss: 1.3001 - val_acc: 0.7701\n",
      "Epoch 76/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.2005 - acc: 0.9036 - val_loss: 1.2996 - val_acc: 0.7693\n",
      "Epoch 77/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.1935 - acc: 0.9058 - val_loss: 1.2905 - val_acc: 0.7676\n",
      "Epoch 78/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.2145 - acc: 0.9020 - val_loss: 1.2985 - val_acc: 0.7701\n",
      "Epoch 79/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.1965 - acc: 0.9058 - val_loss: 1.3028 - val_acc: 0.7684\n",
      "Epoch 80/80\n",
      "148/148 [==============================] - 32s 214ms/step - loss: 1.1894 - acc: 0.9107 - val_loss: 1.2994 - val_acc: 0.7684\n",
      "2021-10-19 20:39:11,773 [INFO] __main__: Total Val Loss: 1.2993652820587158\n",
      "2021-10-19 20:39:11,774 [INFO] __main__: Total Val accuracy: 0.7684478163719177\n",
      "2021-10-19 20:39:11,774 [INFO] __main__: Training finished successfully.\n",
      "2021-10-19 13:39:13,616 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "!tao classification train -e $SPECS_DIR/classification_spec.cfg -r $USER_EXPERIMENT_DIR/output -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To run this training in data parallelism using multiple GPU's, please uncomment the line below and \"\n",
    "      \"update the --gpus parameter to the number of GPU's you wish to use.\")\n",
    "# !tao classification train -e $SPECS_DIR/classification_spec.cfg \\\n",
    "#                       -r $USER_EXPERIMENT_DIR/output \\\n",
    "#                       -k $KEY --gpus 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "      To run this training in model parallelism using multiple GPU's, please uncomment the line below and update the\n",
    "      --gpus parameter to the number of GPU's you wish to use. Also add related parameters in training_config to\n",
    "      enable model parallelism. E.g., \n",
    "\n",
    "             model_parallelism: 50\n",
    "             model_parallelism: 50\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#!tao classification train -e $SPECS_DIR/classification_spec.cfg \\\n",
    "#                       -r $USER_EXPERIMENT_DIR/output \\\n",
    "#                       -k $KEY --gpus 2 \\\n",
    "#                       -np 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To resume from a checkpoint, use --init_epoch along with your checkpoint configured in the spec file.\n",
      "Please make sure that the model_path in the spec file is now updated to the '.tlt' file of the correspondingepoch you wish to resume from. You may choose from the files found under, '$USER_EXPERIMENT_DIR/output/weights' folder.\n",
      "2021-09-22 13:10:27,058 [INFO] root: Registry: ['nvcr.io']\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-r6azev7j because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:281: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:290: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2021-09-22 20:10:33,228 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-09-22 20:10:33,228 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/train.py:302: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-09-22 20:10:33,228 [INFO] __main__: Default image mean [103.939, 116.779, 123.68] will be used.\n",
      "Found 9430 images belonging to 200 classes.\n",
      "2021-09-22 20:10:33,554 [INFO] __main__: Processing dataset (train): /workspace/tao-experiments/data/split/train\n",
      "Found 1179 images belonging to 200 classes.\n",
      "2021-09-22 20:10:33,663 [INFO] __main__: Processing dataset (validation): /workspace/tao-experiments/data/split/val\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-09-22 20:10:33,664 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-09-22 20:10:33,666 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-09-22 20:10:33,679 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-09-22 20:10:33,683 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-09-22 20:10:34,263 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-09-22 20:10:34,804 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-09-22 20:10:34,804 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-09-22 20:10:35,021 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-09-22 20:10:37,449 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-09-22 20:10:37,453 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-09-22 20:10:38,233 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-09-22 20:10:38,332 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 112, 112) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 112, 112) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 112, 112) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 56, 56)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 56, 56)   256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 56, 56)   0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 56, 56)   36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 56, 56)   4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 56, 56)   0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 56, 56)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 56, 56)   36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 56, 56)   0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 56, 56)   36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 56, 56)   4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 56, 56)   0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 56, 56)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 28, 28)  73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 28, 28)  512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 28, 28)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 28, 28)  147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 28, 28)  8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 28, 28)  512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 28, 28)  512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 28, 28)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 28, 28)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 28, 28)  147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 28, 28)  512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 28, 28)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 28, 28)  147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 28, 28)  16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 28, 28)  512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 28, 28)  512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 28, 28)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 28, 28)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 14, 14)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 14, 14)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 14, 14)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 14, 14)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 14, 14)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 14, 14)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 14, 14)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 14, 14)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 14, 14)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 14, 14)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 14, 14)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 14, 14)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 14, 14)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 14, 14)  1179648     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 14, 14)  131072      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 14, 14)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 14, 14)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 14, 14)  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 14, 14)  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 14, 14)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 14, 14)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 512, 1, 1)    0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 200)          102600      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,645,064\n",
      "Trainable params: 11,468,360\n",
      "Non-trainable params: 176,704\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:929: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "2021-09-22 20:10:57,134 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:929: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:931: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2021-09-22 20:10:57,134 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:931: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 40/80\n",
      "  1/148 [..............................] - ETA: 1:05:37 - loss: 2.6467 - acc: 0.5312WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:146: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "2021-09-22 20:11:26,515 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/common/utils.py:146: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "  2/148 [..............................] - ETA: 34:27 - loss: 2.5791 - acc: 0.5156  /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.675898). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "148/148 [==============================] - 62s 419ms/step - loss: 2.4684 - acc: 0.5731 - val_loss: 1.9023 - val_acc: 0.5903\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Bootstrap : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.3<0>\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO NET/Plugin : Plugin load returned 0 : libnccl-net.so: cannot open shared object file: No such file or directory.\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO NET/IB : No device found.\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO NET/Socket : Using [0]lo:127.0.0.1<0> [1]eth0:172.17.0.3<0>\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda11.1\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 00/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 01/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 02/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 03/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 04/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 05/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 06/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 07/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 08/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 09/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 10/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 11/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 12/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 13/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 14/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 15/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 16/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 17/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 18/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 19/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 20/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 21/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 22/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 23/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 24/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 25/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 26/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 27/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 28/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 29/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 30/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Channel 31/32 :    0\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [1] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [2] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [3] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [4] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [5] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [6] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [7] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [8] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [9] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [10] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [11] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [12] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [13] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [14] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [15] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [16] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [17] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [18] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [19] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [20] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [21] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [22] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [23] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [24] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [25] -1/-1/-1->0->-1|-1->0->-1/-1/-1 [26] -1/-1/-1->0->-1|-1->0->-1/\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer\n",
      "8ba41f5e8fb2:82:110 [0] NCCL INFO comm 0x7fa00ef92170 rank 0 nranks 1 cudaDev 0 busId 9000 - Init COMPLETE\n",
      "Epoch 41/80\n",
      "148/148 [==============================] - 33s 222ms/step - loss: 2.4658 - acc: 0.5721 - val_loss: 1.9130 - val_acc: 0.5903\n",
      "Epoch 42/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 2.4743 - acc: 0.5695 - val_loss: 1.8995 - val_acc: 0.5827\n",
      "Epoch 43/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 2.4640 - acc: 0.5749 - val_loss: 1.9064 - val_acc: 0.5963\n",
      "Epoch 44/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 2.4470 - acc: 0.5750 - val_loss: 1.8983 - val_acc: 0.5861\n",
      "Epoch 45/80\n",
      "148/148 [==============================] - 32s 218ms/step - loss: 2.4531 - acc: 0.5741 - val_loss: 1.9190 - val_acc: 0.5878\n",
      "Epoch 46/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 2.4723 - acc: 0.5785 - val_loss: 1.9089 - val_acc: 0.5810\n",
      "Epoch 47/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 2.4602 - acc: 0.5749 - val_loss: 1.9021 - val_acc: 0.5878\n",
      "Epoch 48/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 2.4710 - acc: 0.5754 - val_loss: 1.9102 - val_acc: 0.5886\n",
      "Epoch 49/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 2.4695 - acc: 0.5721 - val_loss: 1.9009 - val_acc: 0.5878\n",
      "Epoch 50/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4917 - acc: 0.5684 - val_loss: 1.8986 - val_acc: 0.5895\n",
      "Epoch 51/80\n",
      "148/148 [==============================] - 33s 221ms/step - loss: 2.4830 - acc: 0.5699 - val_loss: 1.8976 - val_acc: 0.5886\n",
      "Epoch 52/80\n",
      "148/148 [==============================] - 32s 215ms/step - loss: 2.4414 - acc: 0.5742 - val_loss: 1.9229 - val_acc: 0.5861\n",
      "Epoch 53/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 2.4728 - acc: 0.5774 - val_loss: 1.9028 - val_acc: 0.5912\n",
      "Epoch 54/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 2.4686 - acc: 0.5720 - val_loss: 1.9034 - val_acc: 0.5878\n",
      "Epoch 55/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4587 - acc: 0.5768 - val_loss: 1.9081 - val_acc: 0.5844\n",
      "Epoch 56/80\n",
      "148/148 [==============================] - 33s 221ms/step - loss: 2.4593 - acc: 0.5747 - val_loss: 1.9056 - val_acc: 0.5852\n",
      "Epoch 57/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 2.4783 - acc: 0.5736 - val_loss: 1.9072 - val_acc: 0.5903\n",
      "Epoch 58/80\n",
      "148/148 [==============================] - 35s 233ms/step - loss: 2.4661 - acc: 0.5699 - val_loss: 1.9035 - val_acc: 0.5878\n",
      "Epoch 59/80\n",
      "148/148 [==============================] - 34s 228ms/step - loss: 2.4737 - acc: 0.5755 - val_loss: 1.9107 - val_acc: 0.5878\n",
      "Epoch 60/80\n",
      "148/148 [==============================] - 33s 220ms/step - loss: 2.4739 - acc: 0.5754 - val_loss: 1.9140 - val_acc: 0.5827\n",
      "Epoch 61/80\n",
      "148/148 [==============================] - 34s 230ms/step - loss: 2.4760 - acc: 0.5768 - val_loss: 1.9075 - val_acc: 0.5903\n",
      "Epoch 62/80\n",
      "148/148 [==============================] - 35s 234ms/step - loss: 2.4619 - acc: 0.5759 - val_loss: 1.9023 - val_acc: 0.5903\n",
      "Epoch 63/80\n",
      "148/148 [==============================] - 34s 228ms/step - loss: 2.4710 - acc: 0.5730 - val_loss: 1.9022 - val_acc: 0.5869\n",
      "Epoch 64/80\n",
      "148/148 [==============================] - 32s 219ms/step - loss: 2.4513 - acc: 0.5743 - val_loss: 1.9105 - val_acc: 0.5869\n",
      "Epoch 65/80\n",
      "148/148 [==============================] - 34s 227ms/step - loss: 2.4647 - acc: 0.5729 - val_loss: 1.9018 - val_acc: 0.5886\n",
      "Epoch 66/80\n",
      "148/148 [==============================] - 34s 231ms/step - loss: 2.4605 - acc: 0.5712 - val_loss: 1.9051 - val_acc: 0.5844\n",
      "Epoch 67/80\n",
      "148/148 [==============================] - 34s 230ms/step - loss: 2.4441 - acc: 0.5801 - val_loss: 1.9023 - val_acc: 0.5937\n",
      "Epoch 68/80\n",
      "148/148 [==============================] - 33s 224ms/step - loss: 2.4861 - acc: 0.5722 - val_loss: 1.9080 - val_acc: 0.5895\n",
      "Epoch 69/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 2.4701 - acc: 0.5743 - val_loss: 1.9069 - val_acc: 0.5903\n",
      "Epoch 70/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4581 - acc: 0.5749 - val_loss: 1.9107 - val_acc: 0.5886\n",
      "Epoch 71/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4835 - acc: 0.5722 - val_loss: 1.9001 - val_acc: 0.5878\n",
      "Epoch 72/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4497 - acc: 0.5797 - val_loss: 1.9003 - val_acc: 0.5895\n",
      "Epoch 73/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4504 - acc: 0.5762 - val_loss: 1.9037 - val_acc: 0.5852\n",
      "Epoch 74/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4326 - acc: 0.5824 - val_loss: 1.9129 - val_acc: 0.5852\n",
      "Epoch 75/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 2.4433 - acc: 0.5849 - val_loss: 1.8989 - val_acc: 0.5912\n",
      "Epoch 76/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4716 - acc: 0.5701 - val_loss: 1.8946 - val_acc: 0.5937\n",
      "Epoch 77/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 2.4457 - acc: 0.5804 - val_loss: 1.9147 - val_acc: 0.5937\n",
      "Epoch 78/80\n",
      "148/148 [==============================] - 32s 217ms/step - loss: 2.4542 - acc: 0.5773 - val_loss: 1.9119 - val_acc: 0.5861\n",
      "Epoch 79/80\n",
      "148/148 [==============================] - 32s 218ms/step - loss: 2.4692 - acc: 0.5677 - val_loss: 1.9061 - val_acc: 0.5920\n",
      "Epoch 80/80\n",
      "148/148 [==============================] - 32s 216ms/step - loss: 2.4789 - acc: 0.5708 - val_loss: 1.9140 - val_acc: 0.5929\n",
      "2021-09-22 20:34:36,662 [INFO] __main__: Total Val Loss: 1.9139649868011475\n",
      "2021-09-22 20:34:36,662 [INFO] __main__: Total Val accuracy: 0.5928753018379211\n",
      "2021-09-22 20:34:36,662 [INFO] __main__: Training finished successfully.\n",
      "2021-09-22 13:34:38,452 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "print(\"To resume from a checkpoint, use --init_epoch along with your checkpoint configured in the spec file.\")\n",
    "print(\"Please make sure that the model_path in the spec file is now updated to the '.tlt' file of the corresponding\"\n",
    "      \"epoch you wish to resume from. You may choose from the files found under, '$USER_EXPERIMENT_DIR/output/weights' folder.\")\n",
    "!tao classification train -e $SPECS_DIR/classification_spec.cfg \\\n",
    "                       -r $USER_EXPERIMENT_DIR/output \\\n",
    "                       -k $KEY \\\n",
    "                       --init_epoch 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>\n",
    "\n",
    "In this step, we assume that the training is complete and the model from the final epoch (`resnet_080.tlt`) is available. If you would like to run evaluation on an earlier model, please edit the spec file at `$SPECS_DIR/classification_spec.cfg` to point to the intended model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-19 14:08:56,345 [INFO] root: Registry: ['nvcr.io']\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-w4jb39g2 because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2021-10-19 21:09:02,367 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-10-19 21:09:02,367 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-10-19 21:09:02,367 [INFO] __main__: Loading experiment spec at /workspace/tao-experiments/classification/specs/classification_spec.cfg.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-10-19 21:09:02,970 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-10-19 21:09:02,983 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-10-19 21:09:02,990 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-10-19 21:09:02,996 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-10-19 21:09:02,999 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-10-19 21:09:03,586 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-10-19 21:09:03,719 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-10-19 21:09:03,719 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-10-19 21:09:03,719 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-10-19 21:09:03,831 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-10-19 21:09:04,067 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-10-19 21:09:04,069 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-10-19 21:09:04,850 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-10-19 21:09:04,943 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 112, 112) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 112, 112) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 112, 112) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 56, 56)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 56, 56)   256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 56, 56)   0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 56, 56)   36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 56, 56)   4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 56, 56)   0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 56, 56)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 56, 56)   36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 56, 56)   0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 56, 56)   36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 56, 56)   4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 56, 56)   0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 56, 56)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 28, 28)  73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 28, 28)  512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 28, 28)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 28, 28)  147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 28, 28)  8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 28, 28)  512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 28, 28)  512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 28, 28)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 28, 28)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 28, 28)  147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 28, 28)  512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 28, 28)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 28, 28)  147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 128, 28, 28)  16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 28, 28)  512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 128, 28, 28)  512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 28, 28)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 28, 28)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 14, 14)  294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 14, 14)  589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 14, 14)  32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 14, 14)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 14, 14)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 14, 14)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 14, 14)  589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 14, 14)  589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 256, 14, 14)  65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 14, 14)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 256, 14, 14)  1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 14, 14)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 14, 14)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 14, 14)  1179648     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 14, 14)  131072      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 14, 14)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 14, 14)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 14, 14)  2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 14, 14)  262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 14, 14)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 14, 14)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 512, 1, 1)    0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 200)          102600      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,645,064\n",
      "Trainable params: 11,468,360\n",
      "Non-trainable params: 176,704\n",
      "__________________________________________________________________________________________________\n",
      "Found 1179 images belonging to 200 classes.\n",
      "2021-10-19 21:09:07,277 [INFO] __main__: Processing dataset (evaluation): /workspace/tao-experiments/data/split/test\n",
      "Evaluation Loss: 1.374286626738143\n",
      "Evaluation Top K accuracy: 0.76759966138665\n",
      "Found 1179 images belonging to 200 classes.\n",
      "2021-10-19 21:09:11,864 [INFO] __main__: Calculating per-class P/R and confusion matrix. It may take a while...\n",
      "Confusion Matrix\n",
      "[[4 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 6 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 5 0 0]\n",
      " [0 0 0 ... 0 6 0]\n",
      " [0 0 0 ... 0 0 5]]\n",
      "Classification Report\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "            acadian_flycatcher       0.67      0.67      0.67         6\n",
      "                 american_crow       0.27      0.50      0.35         6\n",
      "            american_goldfinch       1.00      1.00      1.00         6\n",
      "                american_pipit       0.57      0.67      0.62         6\n",
      "             american_redstart       1.00      1.00      1.00         6\n",
      "american_three_toed_woodpecker       1.00      1.00      1.00         5\n",
      "              anna_hummingbird       0.67      0.67      0.67         6\n",
      "                    artic_tern       0.83      0.83      0.83         6\n",
      "                 baird_sparrow       1.00      1.00      1.00         5\n",
      "              baltimore_oriole       1.00      1.00      1.00         6\n",
      "                  bank_swallow       0.80      0.67      0.73         6\n",
      "                  barn_swallow       0.71      0.83      0.77         6\n",
      "          bay_breasted_warbler       0.86      1.00      0.92         6\n",
      "             belted_kingfisher       1.00      0.83      0.91         6\n",
      "                   bewick_wren       0.60      0.50      0.55         6\n",
      "       black_and_white_warbler       1.00      1.00      1.00         6\n",
      "           black_billed_cuckoo       0.56      0.83      0.67         6\n",
      "            black_capped_vireo       0.57      0.80      0.67         5\n",
      "        black_footed_albatross       0.56      0.83      0.67         6\n",
      "                    black_tern       0.33      0.17      0.22         6\n",
      "   black_throated_blue_warbler       1.00      0.67      0.80         6\n",
      "        black_throated_sparrow       0.83      0.83      0.83         6\n",
      "                 blue_grosbeak       0.83      0.83      0.83         6\n",
      "             blue_headed_vireo       0.75      0.50      0.60         6\n",
      "                      blue_jay       1.00      0.83      0.91         6\n",
      "           blue_winged_warbler       0.60      1.00      0.75         6\n",
      "           boat_tailed_grackle       0.33      0.33      0.33         6\n",
      "                      bobolink       0.86      1.00      0.92         6\n",
      "              bohemian_waxwing       0.83      0.83      0.83         6\n",
      "              brandt_cormorant       1.00      0.33      0.50         6\n",
      "              brewer_blackbird       0.80      0.67      0.73         6\n",
      "                brewer_sparrow       0.56      0.83      0.67         6\n",
      "               bronzed_cowbird       0.80      0.67      0.73         6\n",
      "                 brown_creeper       1.00      1.00      1.00         6\n",
      "                 brown_pelican       0.71      0.83      0.77         6\n",
      "                brown_thrasher       0.83      0.83      0.83         6\n",
      "                   cactus_wren       0.83      0.83      0.83         6\n",
      "               california_gull       0.45      0.83      0.59         6\n",
      "                canada_warbler       0.57      0.67      0.62         6\n",
      "          cape_glossy_starling       0.75      1.00      0.86         6\n",
      "              cape_may_warbler       1.00      1.00      1.00         6\n",
      "                      cardinal       1.00      0.80      0.89         5\n",
      "                 carolina_wren       0.44      0.67      0.53         6\n",
      "                  caspian_tern       0.40      0.67      0.50         6\n",
      "                 cedar_waxwing       0.86      1.00      0.92         6\n",
      "              cerulean_warbler       0.75      1.00      0.86         6\n",
      "        chestnut_sided_warbler       1.00      0.83      0.91         6\n",
      "              chipping_sparrow       0.50      0.67      0.57         6\n",
      "              chuck_will_widow       1.00      0.83      0.91         6\n",
      "              clark_nutcracker       0.86      1.00      0.92         6\n",
      "          clay_colored_sparrow       0.50      0.50      0.50         6\n",
      "                 cliff_swallow       0.75      0.50      0.60         6\n",
      "                  common_raven       0.57      0.67      0.62         6\n",
      "                   common_tern       0.33      0.50      0.40         6\n",
      "           common_yellowthroat       1.00      1.00      1.00         6\n",
      "                crested_auklet       0.80      1.00      0.89         4\n",
      "               dark_eyed_junco       1.00      1.00      1.00         6\n",
      "              downy_woodpecker       1.00      0.83      0.91         6\n",
      "                   eared_grebe       0.62      0.83      0.71         6\n",
      "                eastern_towhee       0.83      0.83      0.83         6\n",
      "                  elegant_tern       0.50      0.17      0.25         6\n",
      "            european_goldfinch       1.00      1.00      1.00         6\n",
      "              evening_grosbeak       1.00      1.00      1.00         6\n",
      "                 field_sparrow       1.00      0.50      0.67         6\n",
      "                     fish_crow       0.25      0.17      0.20         6\n",
      "                   florida_jay       1.00      0.83      0.91         6\n",
      "                 forsters_tern       0.75      0.50      0.60         6\n",
      "                   fox_sparrow       0.75      1.00      0.86         6\n",
      "                   frigatebird       0.86      1.00      0.92         6\n",
      "                       gadwall       0.67      1.00      0.80         6\n",
      "                     geococcyx       0.86      1.00      0.92         6\n",
      "          glaucous_winged_gull       0.67      1.00      0.80         6\n",
      "         golden_winged_warbler       1.00      1.00      1.00         6\n",
      "           grasshopper_sparrow       0.75      1.00      0.86         6\n",
      "                  gray_catbird       1.00      0.83      0.91         6\n",
      "       gray_crowned_rosy_finch       1.00      1.00      1.00         6\n",
      "                 gray_kingbird       0.80      0.67      0.73         6\n",
      "      great_crested_flycatcher       1.00      0.67      0.80         6\n",
      "             great_grey_shrike       0.44      0.67      0.53         6\n",
      "                     green_jay       0.83      0.83      0.83         6\n",
      "              green_kingfisher       1.00      0.67      0.80         6\n",
      "           green_tailed_towhee       0.83      0.83      0.83         6\n",
      "               green_violetear       0.86      1.00      0.92         6\n",
      "             groove_billed_ani       0.83      0.83      0.83         6\n",
      "                harris_sparrow       1.00      0.83      0.91         6\n",
      "                 heermann_gull       1.00      1.00      1.00         6\n",
      "               henslow_sparrow       0.86      1.00      0.92         6\n",
      "                  herring_gull       0.00      0.00      0.00         6\n",
      "              hooded_merganser       1.00      1.00      1.00         6\n",
      "                 hooded_oriole       0.86      1.00      0.92         6\n",
      "                hooded_warbler       0.80      0.67      0.73         6\n",
      "                  horned_grebe       0.67      0.33      0.44         6\n",
      "                   horned_lark       1.00      1.00      1.00         6\n",
      "                 horned_puffin       1.00      0.83      0.91         6\n",
      "                 house_sparrow       0.67      0.33      0.44         6\n",
      "                    house_wren       0.60      0.50      0.55         6\n",
      "                indigo_bunting       0.83      0.83      0.83         6\n",
      "                    ivory_gull       1.00      1.00      1.00         6\n",
      "              kentucky_warbler       1.00      1.00      1.00         6\n",
      "              laysan_albatross       0.57      0.67      0.62         6\n",
      "                lazuli_bunting       1.00      0.60      0.75         5\n",
      "              le_conte_sparrow       1.00      0.50      0.67         6\n",
      "                  least_auklet       1.00      0.50      0.67         4\n",
      "              least_flycatcher       0.18      0.33      0.24         6\n",
      "                    least_tern       0.67      1.00      0.80         6\n",
      "               lincoln_sparrow       0.67      0.67      0.67         6\n",
      "             loggerhead_shrike       0.57      0.67      0.62         6\n",
      "            long_tailed_jaeger       1.00      0.17      0.29         6\n",
      "         louisiana_waterthrush       1.00      0.67      0.80         6\n",
      "              magnolia_warbler       0.86      1.00      0.92         6\n",
      "                       mallard       0.75      1.00      0.86         6\n",
      "               mangrove_cuckoo       1.00      1.00      1.00         5\n",
      "                    marsh_wren       0.50      0.50      0.50         6\n",
      "                   mockingbird       0.75      0.50      0.60         6\n",
      "              mourning_warbler       0.83      0.83      0.83         6\n",
      "                myrtle_warbler       1.00      0.67      0.80         6\n",
      "             nashville_warbler       0.83      0.83      0.83         6\n",
      "   nelson_sharp_tailed_sparrow       0.67      0.67      0.67         6\n",
      "                     nighthawk       0.67      0.67      0.67         6\n",
      "              northern_flicker       0.83      0.83      0.83         6\n",
      "               northern_fulmar       0.50      0.67      0.57         6\n",
      "          northern_waterthrush       0.83      0.83      0.83         6\n",
      "        olive_sided_flycatcher       0.75      0.50      0.60         6\n",
      "        orange_crowned_warbler       0.83      0.83      0.83         6\n",
      "                orchard_oriole       1.00      0.83      0.91         6\n",
      "                      ovenbird       0.80      0.67      0.73         6\n",
      "                  pacific_loon       1.00      1.00      1.00         6\n",
      "               painted_bunting       1.00      1.00      1.00         6\n",
      "                  palm_warbler       0.83      0.83      0.83         6\n",
      "               parakeet_auklet       0.75      0.60      0.67         5\n",
      "             pelagic_cormorant       0.67      0.67      0.67         6\n",
      "            philadelphia_vireo       0.36      0.67      0.47         6\n",
      "             pied_billed_grebe       1.00      0.83      0.91         6\n",
      "               pied_kingfisher       0.86      1.00      0.92         6\n",
      "              pigeon_guillemot       0.83      1.00      0.91         5\n",
      "           pileated_woodpecker       0.86      1.00      0.92         6\n",
      "                 pine_grosbeak       0.75      1.00      0.86         6\n",
      "                  pine_warbler       0.71      0.83      0.77         6\n",
      "               pomarine_jaeger       0.62      0.83      0.71         6\n",
      "               prairie_warbler       1.00      0.83      0.91         6\n",
      "          prothonotary_warbler       1.00      1.00      1.00         6\n",
      "                  purple_finch       0.80      0.67      0.73         6\n",
      "        red_bellied_woodpecker       1.00      0.83      0.91         6\n",
      "        red_breasted_merganser       1.00      0.67      0.80         6\n",
      "       red_cockaded_woodpecker       0.83      1.00      0.91         5\n",
      "                red_eyed_vireo       0.50      0.67      0.57         6\n",
      "           red_faced_cormorant       0.80      0.80      0.80         5\n",
      "         red_headed_woodpecker       0.67      0.67      0.67         6\n",
      "          red_legged_kittiwake       1.00      1.00      1.00         5\n",
      "          red_winged_blackbird       1.00      1.00      1.00         6\n",
      "             rhinoceros_auklet       0.71      1.00      0.83         5\n",
      "              ring_billed_gull       0.67      0.33      0.44         6\n",
      "             ringed_kingfisher       1.00      1.00      1.00         6\n",
      "                     rock_wren       1.00      0.67      0.80         6\n",
      "        rose_breasted_grosbeak       1.00      0.83      0.91         6\n",
      "     ruby_throated_hummingbird       0.57      0.67      0.62         6\n",
      "            rufous_hummingbird       0.67      0.67      0.67         6\n",
      "               rusty_blackbird       0.43      0.50      0.46         6\n",
      "                 sage_thrasher       0.83      0.83      0.83         6\n",
      "              savannah_sparrow       1.00      0.50      0.67         6\n",
      "                      sayornis       0.75      0.50      0.60         6\n",
      "               scarlet_tanager       0.71      0.83      0.77         6\n",
      "     scissor_tailed_flycatcher       0.75      0.50      0.60         6\n",
      "                  scott_oriole       1.00      0.67      0.80         6\n",
      "               seaside_sparrow       0.67      0.67      0.67         6\n",
      "                 shiny_cowbird       0.67      0.67      0.67         6\n",
      "             slaty_backed_gull       0.50      0.40      0.44         5\n",
      "                  song_sparrow       1.00      1.00      1.00         6\n",
      "               sooty_albatross       0.83      0.83      0.83         6\n",
      "               spotted_catbird       1.00      0.75      0.86         4\n",
      "                summer_tanager       0.83      0.83      0.83         6\n",
      "              swainson_warbler       1.00      0.67      0.80         6\n",
      "             tennessee_warbler       0.67      0.67      0.67         6\n",
      "                  tree_sparrow       1.00      1.00      1.00         6\n",
      "                  tree_swallow       1.00      0.67      0.80         6\n",
      "             tropical_kingbird       1.00      1.00      1.00         6\n",
      "          vermilion_flycatcher       0.86      1.00      0.92         6\n",
      "                vesper_sparrow       0.80      0.67      0.73         6\n",
      "                warbling_vireo       0.33      0.17      0.22         6\n",
      "                 western_grebe       0.86      1.00      0.92         6\n",
      "                  western_gull       0.40      0.33      0.36         6\n",
      "            western_meadowlark       1.00      0.67      0.80         6\n",
      "            western_wood_pewee       0.50      0.50      0.50         6\n",
      "                whip_poor_will       0.57      0.80      0.67         5\n",
      "     white_breasted_kingfisher       1.00      0.83      0.91         6\n",
      "       white_breasted_nuthatch       1.00      1.00      1.00         6\n",
      "         white_crowned_sparrow       0.75      0.50      0.60         6\n",
      "              white_eyed_vireo       0.71      0.83      0.77         6\n",
      "            white_necked_raven       1.00      0.83      0.91         6\n",
      "                 white_pelican       0.83      1.00      0.91         5\n",
      "        white_throated_sparrow       0.75      1.00      0.86         6\n",
      "                wilson_warbler       0.67      1.00      0.80         6\n",
      "                   winter_wren       0.83      0.83      0.83         6\n",
      "           worm_eating_warbler       1.00      0.83      0.91         6\n",
      "     yellow_bellied_flycatcher       0.50      0.33      0.40         6\n",
      "          yellow_billed_cuckoo       0.38      0.50      0.43         6\n",
      "          yellow_breasted_chat       1.00      1.00      1.00         6\n",
      "       yellow_headed_blackbird       1.00      0.83      0.91         6\n",
      "         yellow_throated_vireo       0.67      1.00      0.80         6\n",
      "                yellow_warbler       1.00      0.83      0.91         6\n",
      "\n",
      "                     micro avg       0.77      0.77      0.77      1179\n",
      "                     macro avg       0.79      0.77      0.76      1179\n",
      "                  weighted avg       0.79      0.77      0.76      1179\n",
      "\n",
      "2021-10-19 14:09:18,693 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "!tao classification evaluate -e $SPECS_DIR/classification_spec.cfg -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prune trained models <a class=\"anchor\" id=\"head-6\"></a>\n",
    "* Specify pre-trained model\n",
    "* Equalization criterion\n",
    "* Threshold for pruning\n",
    "* Exclude prediction layer that you don't want pruned (e.g. predictions)\n",
    "\n",
    "Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is depend on the dataset. A pth value 0.68 is just a starting point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: EPOCH=080\n",
      "2021-10-19 14:13:18,729 [INFO] root: Registry: ['nvcr.io']\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-z5whbsxy because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "Using TensorFlow backend.\n",
      "2021-10-19 21:13:26,124 [INFO] modulus.pruning.pruning: Exploring graph for retainable indices\n",
      "2021-10-19 21:13:26,557 [INFO] modulus.pruning.pruning: Pruning model and appending pruned nodes to new graph\n",
      "2021-10-19 21:13:38,358 [INFO] iva.common.magnet_prune: Pruning ratio (pruned model / original model): 0.7593555518458293\n",
      "2021-10-19 14:13:39,756 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# Defining the checkpoint epoch number of the model to be used for the pruning.\n",
    "# This should be lesser than the number of epochs training has been run for, incase training was interrupted earlier.\n",
    "# By default, the default final model is at epoch 080.\n",
    "%env EPOCH=080\n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/output/vgg_pruned\n",
    "!tao classification prune -m $USER_EXPERIMENT_DIR/output/weights/vgg_$EPOCH.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/output/vgg_pruned/vgg19_nopool_bn_pruned.tlt \\\n",
    "           -eq union \\\n",
    "           -pth 0.6 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model:\n",
      "------------\n",
      "vgg19_nopool_bn_pruned.tlt\n"
     ]
    }
   ],
   "source": [
    "print('Pruned model:')\n",
    "print('------------')\n",
    "!ls -r1t $LOCAL_EXPERIMENT_DIR/output/vgg_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Retrain pruned models <a class=\"anchor\" id=\"head-7\"></a>\n",
    "* Model needs to be re-trained to bring back accuracy after pruning\n",
    "* Specify re-training specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $LOCAL_SPECS_DIR/classification_retrain_spec.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao classification train -e $SPECS_DIR/classification_retrain_spec.cfg \\\n",
    "                      -r $USER_EXPERIMENT_DIR/output_retrain \\\n",
    "                      -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Testing the model! <a class=\"anchor\" id=\"head-8\"></a>\n",
    "\n",
    "In this step, we assume that the training is complete and the model from the final epoch (`resnet_080.tlt`) is available. If you would like to run evaluation on an earlier model, please edit the spec file at `$SPECS_DIR/classification_retrain_spec.cfg` to point to the intended model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 10:38:43,253 [INFO] root: Registry: ['nvcr.io']\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-3816bz6m because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "2021-12-06 18:38:49,014 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-12-06 18:38:49,014 [WARNING] tensorflow: From /root/.cache/bazel/_bazel_root/ed34e6d125608f91724fda23656f1726/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/makenet/scripts/evaluate.py:77: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "2021-12-06 18:38:49,014 [INFO] __main__: Loading experiment spec at /workspace/tao-experiments/classification/specs/classification_retrain_spec.cfg.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2021-12-06 18:38:49,506 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2021-12-06 18:38:49,520 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2021-12-06 18:38:49,529 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2021-12-06 18:38:49,536 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2021-12-06 18:38:49,539 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2021-12-06 18:38:50,110 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2021-12-06 18:38:50,239 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2021-12-06 18:38:50,239 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2021-12-06 18:38:50,240 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2021-12-06 18:38:50,368 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "2021-12-06 18:38:50,618 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "2021-12-06 18:38:50,620 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "2021-12-06 18:38:51,389 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "2021-12-06 18:38:51,480 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 112, 112) 2352        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 112, 112) 64          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 112, 112) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 48, 56, 56)   6912        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 48, 56, 56)   192         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 48, 56, 56)   0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 48, 56, 56)   20736       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 48, 56, 56)   768         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 48, 56, 56)   192         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 48, 56, 56)   192         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 56, 56)   0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 48, 56, 56)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 16, 56, 56)   6912        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 16, 56, 56)   64          block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 16, 56, 56)   0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 56, 56)   9216        block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (None, 64, 56, 56)   3072        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 56, 56)   256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (None, 64, 56, 56)   256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 56, 56)   0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 56, 56)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 120, 28, 28)  69120       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 120, 28, 28)  480         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 120, 28, 28)  0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 120, 28, 28)  129600      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 120, 28, 28)  7680        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 120, 28, 28)  480         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 120, 28, 28)  480         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 120, 28, 28)  0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 120, 28, 28)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 104, 28, 28)  112320      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 104, 28, 28)  416         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 104, 28, 28)  0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 112, 28, 28)  104832      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (None, 112, 28, 28)  13440       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 112, 28, 28)  448         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (None, 112, 28, 28)  448         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 112, 28, 28)  0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 112, 28, 28)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 14, 14)  258048      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 14, 14)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 14, 14)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 248, 14, 14)  571392      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 248, 14, 14)  27776       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 248, 14, 14)  992         block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 248, 14, 14)  992         block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 248, 14, 14)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 248, 14, 14)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 176, 14, 14)  392832      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 176, 14, 14)  704         block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 176, 14, 14)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 200, 14, 14)  316800      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (None, 200, 14, 14)  49600       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 200, 14, 14)  800         block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (None, 200, 14, 14)  800         block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 200, 14, 14)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 200, 14, 14)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 480, 14, 14)  864000      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 480, 14, 14)  1920        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 480, 14, 14)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 352, 14, 14)  1520640     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 352, 14, 14)  70400       block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 352, 14, 14)  1408        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 352, 14, 14)  1408        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 352, 14, 14)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 352, 14, 14)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 14, 14)  1622016     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 14, 14)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 14, 14)  2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (None, 512, 14, 14)  180224      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 14, 14)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (None, 512, 14, 14)  2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 14, 14)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 14, 14)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 512, 1, 1)    0           block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 200)          102600      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,842,744\n",
      "Trainable params: 8,782,696\n",
      "Non-trainable params: 60,048\n",
      "__________________________________________________________________________________________________\n",
      "Found 1179 images belonging to 200 classes.\n",
      "2021-12-06 18:38:53,838 [INFO] __main__: Processing dataset (evaluation): /workspace/tao-experiments/data/split/test\n",
      "Evaluation Loss: 1.4726403314648693\n",
      "Evaluation Top K accuracy: 0.8770144189991518\n",
      "Found 1179 images belonging to 200 classes.\n",
      "2021-12-06 18:39:00,058 [INFO] __main__: Calculating per-class P/R and confusion matrix. It may take a while...\n",
      "Confusion Matrix\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 4 0 ... 0 0 0]\n",
      " [0 0 6 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 6 0 0]\n",
      " [0 0 0 ... 0 6 0]\n",
      " [0 0 0 ... 0 0 6]]\n",
      "Classification Report\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "            acadian_flycatcher       0.60      0.50      0.55         6\n",
      "                 american_crow       0.36      0.67      0.47         6\n",
      "            american_goldfinch       1.00      1.00      1.00         6\n",
      "                american_pipit       0.67      0.33      0.44         6\n",
      "             american_redstart       0.86      1.00      0.92         6\n",
      "american_three_toed_woodpecker       1.00      0.80      0.89         5\n",
      "              anna_hummingbird       0.60      0.50      0.55         6\n",
      "                    artic_tern       0.83      0.83      0.83         6\n",
      "                 baird_sparrow       0.62      1.00      0.77         5\n",
      "              baltimore_oriole       0.86      1.00      0.92         6\n",
      "                  bank_swallow       0.80      0.67      0.73         6\n",
      "                  barn_swallow       0.71      0.83      0.77         6\n",
      "          bay_breasted_warbler       0.75      1.00      0.86         6\n",
      "             belted_kingfisher       1.00      0.83      0.91         6\n",
      "                   bewick_wren       0.67      0.67      0.67         6\n",
      "       black_and_white_warbler       1.00      1.00      1.00         6\n",
      "           black_billed_cuckoo       0.62      0.83      0.71         6\n",
      "            black_capped_vireo       0.80      0.80      0.80         5\n",
      "        black_footed_albatross       0.43      0.50      0.46         6\n",
      "                    black_tern       0.50      0.17      0.25         6\n",
      "   black_throated_blue_warbler       0.67      0.33      0.44         6\n",
      "        black_throated_sparrow       0.83      0.83      0.83         6\n",
      "                 blue_grosbeak       0.80      0.67      0.73         6\n",
      "             blue_headed_vireo       0.62      0.83      0.71         6\n",
      "                      blue_jay       1.00      0.83      0.91         6\n",
      "           blue_winged_warbler       0.80      0.67      0.73         6\n",
      "           boat_tailed_grackle       0.40      0.33      0.36         6\n",
      "                      bobolink       0.86      1.00      0.92         6\n",
      "              bohemian_waxwing       0.86      1.00      0.92         6\n",
      "              brandt_cormorant       1.00      0.17      0.29         6\n",
      "              brewer_blackbird       0.80      0.67      0.73         6\n",
      "                brewer_sparrow       0.56      0.83      0.67         6\n",
      "               bronzed_cowbird       1.00      0.83      0.91         6\n",
      "                 brown_creeper       1.00      1.00      1.00         6\n",
      "                 brown_pelican       0.75      1.00      0.86         6\n",
      "                brown_thrasher       0.71      0.83      0.77         6\n",
      "                   cactus_wren       0.83      0.83      0.83         6\n",
      "               california_gull       0.29      0.33      0.31         6\n",
      "                canada_warbler       1.00      0.67      0.80         6\n",
      "          cape_glossy_starling       0.86      1.00      0.92         6\n",
      "              cape_may_warbler       1.00      1.00      1.00         6\n",
      "                      cardinal       1.00      0.80      0.89         5\n",
      "                 carolina_wren       0.56      0.83      0.67         6\n",
      "                  caspian_tern       0.50      0.50      0.50         6\n",
      "                 cedar_waxwing       0.86      1.00      0.92         6\n",
      "              cerulean_warbler       0.86      1.00      0.92         6\n",
      "        chestnut_sided_warbler       1.00      0.67      0.80         6\n",
      "              chipping_sparrow       0.67      0.67      0.67         6\n",
      "              chuck_will_widow       0.80      0.67      0.73         6\n",
      "              clark_nutcracker       0.75      1.00      0.86         6\n",
      "          clay_colored_sparrow       0.71      0.83      0.77         6\n",
      "                 cliff_swallow       0.50      0.33      0.40         6\n",
      "                  common_raven       0.62      0.83      0.71         6\n",
      "                   common_tern       0.50      0.50      0.50         6\n",
      "           common_yellowthroat       0.75      1.00      0.86         6\n",
      "                crested_auklet       0.80      1.00      0.89         4\n",
      "               dark_eyed_junco       1.00      1.00      1.00         6\n",
      "              downy_woodpecker       1.00      1.00      1.00         6\n",
      "                   eared_grebe       0.62      0.83      0.71         6\n",
      "                eastern_towhee       0.83      0.83      0.83         6\n",
      "                  elegant_tern       0.50      0.33      0.40         6\n",
      "            european_goldfinch       0.75      1.00      0.86         6\n",
      "              evening_grosbeak       1.00      1.00      1.00         6\n",
      "                 field_sparrow       0.50      0.50      0.50         6\n",
      "                     fish_crow       0.00      0.00      0.00         6\n",
      "                   florida_jay       0.83      0.83      0.83         6\n",
      "                 forsters_tern       0.60      0.50      0.55         6\n",
      "                   fox_sparrow       1.00      1.00      1.00         6\n",
      "                   frigatebird       0.42      0.83      0.56         6\n",
      "                       gadwall       0.67      1.00      0.80         6\n",
      "                     geococcyx       0.86      1.00      0.92         6\n",
      "          glaucous_winged_gull       0.55      1.00      0.71         6\n",
      "         golden_winged_warbler       1.00      1.00      1.00         6\n",
      "           grasshopper_sparrow       0.62      0.83      0.71         6\n",
      "                  gray_catbird       1.00      0.83      0.91         6\n",
      "       gray_crowned_rosy_finch       1.00      0.83      0.91         6\n",
      "                 gray_kingbird       1.00      0.67      0.80         6\n",
      "      great_crested_flycatcher       1.00      0.50      0.67         6\n",
      "             great_grey_shrike       0.44      0.67      0.53         6\n",
      "                     green_jay       1.00      0.83      0.91         6\n",
      "              green_kingfisher       0.60      0.50      0.55         6\n",
      "           green_tailed_towhee       1.00      0.83      0.91         6\n",
      "               green_violetear       0.86      1.00      0.92         6\n",
      "             groove_billed_ani       0.67      0.67      0.67         6\n",
      "                harris_sparrow       0.83      0.83      0.83         6\n",
      "                 heermann_gull       0.86      1.00      0.92         6\n",
      "               henslow_sparrow       0.71      0.83      0.77         6\n",
      "                  herring_gull       0.33      0.17      0.22         6\n",
      "              hooded_merganser       1.00      0.83      0.91         6\n",
      "                 hooded_oriole       1.00      0.83      0.91         6\n",
      "                hooded_warbler       1.00      0.67      0.80         6\n",
      "                  horned_grebe       1.00      0.33      0.50         6\n",
      "                   horned_lark       1.00      0.83      0.91         6\n",
      "                 horned_puffin       1.00      1.00      1.00         6\n",
      "                 house_sparrow       0.67      0.33      0.44         6\n",
      "                    house_wren       0.60      0.50      0.55         6\n",
      "                indigo_bunting       0.83      0.83      0.83         6\n",
      "                    ivory_gull       0.75      1.00      0.86         6\n",
      "              kentucky_warbler       1.00      0.83      0.91         6\n",
      "              laysan_albatross       0.57      0.67      0.62         6\n",
      "                lazuli_bunting       0.75      0.60      0.67         5\n",
      "              le_conte_sparrow       1.00      0.33      0.50         6\n",
      "                  least_auklet       0.50      0.50      0.50         4\n",
      "              least_flycatcher       0.33      0.50      0.40         6\n",
      "                    least_tern       0.75      1.00      0.86         6\n",
      "               lincoln_sparrow       0.80      0.67      0.73         6\n",
      "             loggerhead_shrike       0.50      0.50      0.50         6\n",
      "            long_tailed_jaeger       0.67      0.33      0.44         6\n",
      "         louisiana_waterthrush       1.00      0.83      0.91         6\n",
      "              magnolia_warbler       1.00      0.83      0.91         6\n",
      "                       mallard       1.00      1.00      1.00         6\n",
      "               mangrove_cuckoo       0.83      1.00      0.91         5\n",
      "                    marsh_wren       0.50      0.50      0.50         6\n",
      "                   mockingbird       0.67      0.33      0.44         6\n",
      "              mourning_warbler       0.50      0.50      0.50         6\n",
      "                myrtle_warbler       1.00      0.83      0.91         6\n",
      "             nashville_warbler       0.75      1.00      0.86         6\n",
      "   nelson_sharp_tailed_sparrow       0.67      0.67      0.67         6\n",
      "                     nighthawk       0.67      0.67      0.67         6\n",
      "              northern_flicker       1.00      0.83      0.91         6\n",
      "               northern_fulmar       0.71      0.83      0.77         6\n",
      "          northern_waterthrush       0.60      1.00      0.75         6\n",
      "        olive_sided_flycatcher       0.67      0.67      0.67         6\n",
      "        orange_crowned_warbler       0.60      0.50      0.55         6\n",
      "                orchard_oriole       1.00      0.67      0.80         6\n",
      "                      ovenbird       1.00      0.67      0.80         6\n",
      "                  pacific_loon       1.00      1.00      1.00         6\n",
      "               painted_bunting       1.00      1.00      1.00         6\n",
      "                  palm_warbler       0.67      0.67      0.67         6\n",
      "               parakeet_auklet       1.00      0.80      0.89         5\n",
      "             pelagic_cormorant       0.50      0.50      0.50         6\n",
      "            philadelphia_vireo       0.44      0.67      0.53         6\n",
      "             pied_billed_grebe       0.83      0.83      0.83         6\n",
      "               pied_kingfisher       0.71      0.83      0.77         6\n",
      "              pigeon_guillemot       0.67      0.80      0.73         5\n",
      "           pileated_woodpecker       0.75      1.00      0.86         6\n",
      "                 pine_grosbeak       0.86      1.00      0.92         6\n",
      "                  pine_warbler       0.71      0.83      0.77         6\n",
      "               pomarine_jaeger       0.75      1.00      0.86         6\n",
      "               prairie_warbler       0.67      0.67      0.67         6\n",
      "          prothonotary_warbler       1.00      1.00      1.00         6\n",
      "                  purple_finch       0.83      0.83      0.83         6\n",
      "        red_bellied_woodpecker       1.00      0.83      0.91         6\n",
      "        red_breasted_merganser       1.00      0.67      0.80         6\n",
      "       red_cockaded_woodpecker       1.00      1.00      1.00         5\n",
      "                red_eyed_vireo       0.80      0.67      0.73         6\n",
      "           red_faced_cormorant       0.67      0.80      0.73         5\n",
      "         red_headed_woodpecker       1.00      0.50      0.67         6\n",
      "          red_legged_kittiwake       0.80      0.80      0.80         5\n",
      "          red_winged_blackbird       0.83      0.83      0.83         6\n",
      "             rhinoceros_auklet       1.00      0.80      0.89         5\n",
      "              ring_billed_gull       0.25      0.17      0.20         6\n",
      "             ringed_kingfisher       0.80      0.67      0.73         6\n",
      "                     rock_wren       0.67      0.67      0.67         6\n",
      "        rose_breasted_grosbeak       0.83      0.83      0.83         6\n",
      "     ruby_throated_hummingbird       0.75      0.50      0.60         6\n",
      "            rufous_hummingbird       0.71      0.83      0.77         6\n",
      "               rusty_blackbird       0.50      0.67      0.57         6\n",
      "                 sage_thrasher       0.75      1.00      0.86         6\n",
      "              savannah_sparrow       1.00      0.50      0.67         6\n",
      "                      sayornis       1.00      0.67      0.80         6\n",
      "               scarlet_tanager       0.80      0.67      0.73         6\n",
      "     scissor_tailed_flycatcher       0.60      0.50      0.55         6\n",
      "                  scott_oriole       1.00      1.00      1.00         6\n",
      "               seaside_sparrow       0.80      0.67      0.73         6\n",
      "                 shiny_cowbird       0.75      0.50      0.60         6\n",
      "             slaty_backed_gull       0.50      0.20      0.29         5\n",
      "                  song_sparrow       1.00      1.00      1.00         6\n",
      "               sooty_albatross       0.80      0.67      0.73         6\n",
      "               spotted_catbird       1.00      1.00      1.00         4\n",
      "                summer_tanager       0.83      0.83      0.83         6\n",
      "              swainson_warbler       1.00      0.67      0.80         6\n",
      "             tennessee_warbler       0.38      0.50      0.43         6\n",
      "                  tree_sparrow       0.83      0.83      0.83         6\n",
      "                  tree_swallow       0.80      0.67      0.73         6\n",
      "             tropical_kingbird       1.00      1.00      1.00         6\n",
      "          vermilion_flycatcher       1.00      1.00      1.00         6\n",
      "                vesper_sparrow       0.67      0.67      0.67         6\n",
      "                warbling_vireo       0.50      0.50      0.50         6\n",
      "                 western_grebe       0.86      1.00      0.92         6\n",
      "                  western_gull       0.38      0.50      0.43         6\n",
      "            western_meadowlark       0.83      0.83      0.83         6\n",
      "            western_wood_pewee       0.80      0.67      0.73         6\n",
      "                whip_poor_will       0.57      0.80      0.67         5\n",
      "     white_breasted_kingfisher       1.00      0.67      0.80         6\n",
      "       white_breasted_nuthatch       1.00      1.00      1.00         6\n",
      "         white_crowned_sparrow       1.00      0.83      0.91         6\n",
      "              white_eyed_vireo       0.67      0.67      0.67         6\n",
      "            white_necked_raven       1.00      0.83      0.91         6\n",
      "                 white_pelican       0.71      1.00      0.83         5\n",
      "        white_throated_sparrow       0.75      1.00      0.86         6\n",
      "                wilson_warbler       0.67      1.00      0.80         6\n",
      "                   winter_wren       0.83      0.83      0.83         6\n",
      "           worm_eating_warbler       0.75      1.00      0.86         6\n",
      "     yellow_bellied_flycatcher       0.40      0.33      0.36         6\n",
      "          yellow_billed_cuckoo       0.43      0.50      0.46         6\n",
      "          yellow_breasted_chat       1.00      1.00      1.00         6\n",
      "       yellow_headed_blackbird       0.75      1.00      0.86         6\n",
      "         yellow_throated_vireo       0.60      1.00      0.75         6\n",
      "                yellow_warbler       1.00      1.00      1.00         6\n",
      "\n",
      "                     micro avg       0.75      0.75      0.75      1179\n",
      "                     macro avg       0.77      0.75      0.75      1179\n",
      "                  weighted avg       0.77      0.75      0.75      1179\n",
      "\n",
      "2021-12-06 10:39:06,919 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "!tao classification evaluate -e $SPECS_DIR/classification_retrain_spec.cfg -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Inferences <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the output results of our model on test images, we can use the `tlt-infer` tool. Note that using models trained for higher epochs will usually result in better results. We'll run inference with the directory mode. You can also use the single image mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the checkpoint epoch number to use for the subsequent steps.\n",
    "# This should be lesser than the number of epochs training has been run for, incase training was interrupted earlier.\n",
    "# By default, the default final model is at epoch 080.\n",
    "%env EPOCH=080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao classification inference -e $SPECS_DIR/classification_retrain_spec.cfg \\\n",
    "                          -m $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_$EPOCH.tlt \\\n",
    "                          -k $KEY -b 32 -d $DATA_DOWNLOAD_DIR/split/test/person \\\n",
    "                          -cm $USER_EXPERIMENT_DIR/output_retrain/classmap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in Getting Started Guide, this outputs a results.csv file in the same directory. We can use a simple python program to see the visualize the output of csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import os\n",
    "import csv\n",
    "from math import ceil\n",
    "\n",
    "DATA_DIR = os.environ.get('LOCAL_DATA_DIR')\n",
    "DATA_DOWNLOAD_DIR = os.environ.get('DATA_DOWNLOAD_DIR')\n",
    "csv_path = os.path.join(DATA_DIR, 'split', 'test', 'person', 'result.csv')\n",
    "results = []\n",
    "with open(csv_path) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        results.append((row[0], row[1]))\n",
    "\n",
    "w,h = 200,200\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "columns = 5\n",
    "rows = 1\n",
    "for i in range(1, columns*rows + 1):\n",
    "    ax = fig.add_subplot(rows, columns,i)\n",
    "    img = Image.open(results[i][0].replace(DATA_DOWNLOAD_DIR, DATA_DIR))\n",
    "    img = img.resize((w,h), Image.ANTIALIAS)\n",
    "    plt.imshow(img)\n",
    "    ax.set_title(results[i][1], fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export and Deploy! <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao classification export \\\n",
    "            -m $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_$EPOCH.tlt \\\n",
    "            -o $USER_EXPERIMENT_DIR/export/final_model.etlt \\\n",
    "            -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lh $LOCAL_EXPERIMENT_DIR/export/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Int8 Optimization <a class=\"anchor\" id=\"head-9-1\"></a>\n",
    "Classification model supports int8 optimization for inference in TRT. Inorder to use this, we must calibrate the model to run 8-bit inferences. This involves 2 steps\n",
    "\n",
    "* Generate calibration tensorfile from the training data using tlt-int8-tensorfile\n",
    "* Use tao <task> export to generate int8 calibration table.\n",
    "\n",
    "*Note: For this example, we generate a calibration tensorfile containing 10 batches of training data.\n",
    "Ideally, it is best to use atleast 10-20% of the training data to calibrate the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao classification calibration_tensorfile -e $SPECS_DIR/classification_retrain_spec.cfg \\\n",
    "                                    -m 10 \\\n",
    "                                    -o $USER_EXPERIMENT_DIR/export/calibration.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the pre-existing exported .etlt file.\n",
    "!rm -rf $LOCAL_EXPERIMENT_DIR/export/final_model.etlt\n",
    "!tao classification export \\\n",
    "            -m $USER_EXPERIMENT_DIR/output_retrain/weights/resnet_$EPOCH.tlt \\\n",
    "            -o $USER_EXPERIMENT_DIR/export/final_model.etlt \\\n",
    "            -k $KEY \\\n",
    "            --cal_data_file $USER_EXPERIMENT_DIR/export/calibration.tensor \\\n",
    "            --data_type int8 \\\n",
    "            --batches 10 \\\n",
    "            --cal_cache_file $USER_EXPERIMENT_DIR/export/final_model_int8_cache.bin \\\n",
    "            -v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Generate TensorRT engine <a class=\"anchor\" id=\"head-9-2\"></a>\n",
    "Verify engine generation using the `tao-converter` utility included with the docker.\n",
    "\n",
    "The `tao-converter` produces optimized tensorrt engines for the platform that it resides on. Therefore, to get maximum performance, please instantiate this docker and execute the `tao-converter` command, with the exported `.etlt` file and calibration cache (for int8 mode) on your target device. The tao-converter utility included in this docker only works for x86 devices, with discrete NVIDIA GPU's. \n",
    "\n",
    "For the jetson devices, please download the tao-converter for jetson from the dev zone link [here](https://developer.nvidia.com/tao-converter). \n",
    "\n",
    "If you choose to integrate your model into deepstream directly, you may do so by simply copying the exported `.etlt` file along with the calibration cache to the target device and updating the spec file that configures the `gst-nvinfer` element to point to this newly exported model. Usually this file is called `config_infer_primary.txt` for detection models and `config_infer_secondary_*.txt` for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao converter $USER_EXPERIMENT_DIR/export/final_model.etlt \\\n",
    "               -k $KEY \\\n",
    "               -c $USER_EXPERIMENT_DIR/export/final_model_int8_cache.bin \\\n",
    "               -o predictions/Softmax \\\n",
    "               -d 3,224,224 \\\n",
    "               -i nchw \\\n",
    "               -m 64 -t int8 \\\n",
    "               -e $USER_EXPERIMENT_DIR/export/final_model.trt \\\n",
    "               -b 64"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07ed8c4fc7e54243077e4d9940a71f9aa4c2835d120b27641e36d79c2dc3e6ec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tao-toolkit': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
